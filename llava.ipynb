{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fd8ccf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка модели через pipeline... Это займет много времени и VRAM.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e9387ee3ba4fc6ae8b534cf1857242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/950 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\basal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\basal\\.cache\\huggingface\\hub\\models--llava-hf--llava-1.5-7b-hf. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Ошибка загрузки модели: Could not load model llava-hf/llava-1.5-7b-hf with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForVision2Seq'>, <class 'transformers.models.llava.modeling_llava.LlavaForConditionalGeneration'>). See the original errors:\n",
      "\n",
      "while loading with AutoModelForVision2Seq, an error is thrown:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\basal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 293, in infer_framework_load_model\n",
      "    model = model_class.from_pretrained(model, **kwargs)\n",
      "  File \"c:\\Users\\basal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py\", line 2289, in from_pretrained\n",
      "    return super().from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\basal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 604, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\basal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 277, in _wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\basal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4806, in from_pretrained\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\basal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 311, in infer_framework_load_model\n",
      "    model = model_class.from_pretrained(model, **fp32_kwargs)\n",
      "  File \"c:\\Users\\basal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py\", line 2289, in from_pretrained\n",
      "    return super().from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\basal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 604, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\basal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 277, in _wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\basal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4806, in from_pretrained\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`\n",
      "\n",
      "while loading with LlavaForConditionalGeneration, an error is thrown:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\basal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 293, in infer_framework_load_model\n",
      "    model = model_class.from_pretrained(model, **kwargs)\n",
      "  File \"c:\\Users\\basal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 277, in _wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\basal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4806, in from_pretrained\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\basal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 311, in infer_framework_load_model\n",
      "    model = model_class.from_pretrained(model, **fp32_kwargs)\n",
      "  File \"c:\\Users\\basal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 277, in _wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\basal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4806, in from_pretrained\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`\n",
      "\n",
      "\n",
      ". Возможно, не хватает VRAM.\n",
      "❌ Основной процесс не был запущен из-за ошибки загрузки модели.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\basal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:2284: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Конфигурация ---\n",
    "# Используем 7B-версию, так как 13B не поместится в VRAM\n",
    "MODEL_ID = \"llava-hf/llava-1.5-7b-hf\"\n",
    "IMG_DIR = \"img\"\n",
    "RESULTS_FILE = \"llava_pipeline_7b_results.csv\"\n",
    "PROMPT_TEMPLATE = \"USER: <image>\\n{prompt}\\nASSISTANT:\"\n",
    "PROMPT_QUESTION = \"Скажи, изображена ли на данном фото кошка породы \\\"Британская короткошерстная\\\", дай коротки ответ \\\"да\\\" или \\\"нет\\\". Опиши одним словом каждый признак, который убедил тебя в правильности или неправильности ответа. Если это не британская короткошерстная кошка, скажи какая это порода.\"\n",
    "\n",
    "# --- 2. Загрузка модели через pipeline ---\n",
    "pipe = None\n",
    "print(\"Загрузка модели через pipeline... Это займет много времени и VRAM.\")\n",
    "try:\n",
    "    pipe = pipeline(\n",
    "        \"image-to-text\",\n",
    "        model=MODEL_ID,\n",
    "        torch_dtype=torch.float16, # Используем половинную точность для экономии памяти\n",
    "        device_map=\"auto\" # Автоматически использовать GPU\n",
    "    )\n",
    "    print(\"✅ Модель успешно загружена!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Ошибка загрузки модели: {e}. Возможно, не хватает VRAM.\")\n",
    "\n",
    "# --- 3. Основной цикл обработки ---\n",
    "if pipe:\n",
    "    try:\n",
    "        image_files = sorted([f for f in os.listdir(IMG_DIR) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        results_data = []\n",
    "        \n",
    "        print(f\"Начинаем обработку {len(image_files)} изображений...\")\n",
    "        for filename in tqdm(image_files, desc=\"LLaVA Pipeline 7B\"):\n",
    "            image_path = os.path.join(IMG_DIR, filename)\n",
    "            \n",
    "            try:\n",
    "                # Открываем изображение\n",
    "                image = Image.open(image_path)\n",
    "                # Форматируем промпт правильно для LLaVA\n",
    "                prompt = PROMPT_TEMPLATE.format(prompt=PROMPT_QUESTION)\n",
    "                \n",
    "                # Запускаем генерацию\n",
    "                outputs = pipe(image, prompt=prompt, generate_kwargs={\"max_new_tokens\": 50})\n",
    "                \n",
    "                # Извлекаем только ответ ассистента\n",
    "                full_text = outputs[0][\"generated_text\"]\n",
    "                result_text = full_text.split(\"ASSISTANT:\")[1].strip()\n",
    "                results_data.append({\"filename\": filename, \"llava_7b_response\": result_text})\n",
    "\n",
    "            except Exception as e:\n",
    "                results_data.append({\"filename\": filename, \"llava_7b_response\": f\"Error: {e}\"})\n",
    "\n",
    "        df_results = pd.DataFrame(results_data)\n",
    "        df_results.to_csv(RESULTS_FILE, index=False, encoding='utf-8')\n",
    "        print(f\"✅ Результаты сохранены в '{RESULTS_FILE}'.\")\n",
    "        display(df_results.head())\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ Ошибка: Директория '{IMG_DIR}' не найдена.\")\n",
    "else:\n",
    "    print(\"❌ Основной процесс не был запущен из-за ошибки загрузки модели.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
