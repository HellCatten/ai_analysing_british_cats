{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d56d5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка моделей...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_new_context_with_model: n_ctx_per_seq (4096) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Модели успешно загружены!\n",
      "Начинаем обработку 30 изображений для получения развернутых ответов...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLaVA Local 7B (Detailed): 100%|██████████| 30/30 [29:59<00:00, 59.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Результаты сохранены в 'llava_local_7b_detailed_results.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>llava_7b_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brit1.jpg</td>\n",
       "      <td>1.  **Анализ признаков:** Ключевые видимые при...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brit10.jpg</td>\n",
       "      <td>1. **Анализ признаков:** Ключевые видимые приз...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brit2.jpg</td>\n",
       "      <td>1.  **Анализ признаков:** Кошка в изображении ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brit3.jpg</td>\n",
       "      <td>1. **Анализ признаков:** В изображении видны к...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brit4.jpg</td>\n",
       "      <td>1. В изображении видны ключевые признаки: кошк...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename                                  llava_7b_response\n",
       "0   brit1.jpg  1.  **Анализ признаков:** Ключевые видимые при...\n",
       "1  brit10.jpg  1. **Анализ признаков:** Ключевые видимые приз...\n",
       "2   brit2.jpg  1.  **Анализ признаков:** Кошка в изображении ...\n",
       "3   brit3.jpg  1. **Анализ признаков:** В изображении видны к...\n",
       "4   brit4.jpg  1. В изображении видны ключевые признаки: кошк..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from llama_cpp import Llama\n",
    "from llama_cpp.llama_chat_format import Llava15ChatHandler\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# --- 1. Конфигурация ---\n",
    "MODEL_PATH = \"./models/llava-v1.6-mistral-7b.Q4_K_M.gguf\" \n",
    "CLIP_MODEL_PATH = \"./models/mmproj-model-f16.gguf\"\n",
    "IMG_DIR = \"img\"\n",
    "TEMP_IMG_DIR = \"img_resized\" \n",
    "os.makedirs(TEMP_IMG_DIR, exist_ok=True)\n",
    "RESULTS_FILE = \"llava_local_7b_detailed_results.csv\" # Новое имя файла\n",
    "\n",
    "# <-- 1. НОВЫЙ, СТРУКТУРИРОВАННЫЙ \"CHAIN OF THOUGHT\" ПРОМПТ\n",
    "# Мы даем модели шаблон, который она должна заполнить.\n",
    "PROMPT = \"\"\"Ты — эксперт по определению пород кошек. Проанализируй изображение по следующему плану:\n",
    "\n",
    "1.  **Анализ признаков:** Опиши одним-двумя словами ключевые видимые признаки кошки (форма головы, уши, шерсть, телосложение, цвет глаз).\n",
    "2.  **Сравнение с породой \"Британская короткошерстная\":** Сравни проанализированные признаки с эталоном британской породы.\n",
    "3.  **Итоговый вердикт:** Дай короткий ответ \"Да\" или \"Нет\".\n",
    "4.  **Альтернативная порода (если вердикт \"Нет\"):** Если это не британская кошка, укажи наиболее вероятную породу.\n",
    "\n",
    "Ответ дай строго по этому плану.\"\"\"\n",
    "\n",
    "# --- 2. Настройки производительности и генерации ---\n",
    "N_GPU_LAYERS = -1\n",
    "N_CTX = 4096\n",
    "N_BATCH = 1024\n",
    "N_THREADS = os.cpu_count()\n",
    "\n",
    "# <-- 2. ИЗМЕНЯЕМ ПАРАМЕТРЫ ГЕНЕРАЦИИ ДЛЯ РАЗВЕРНУТОГО ОТВЕТА\n",
    "TEMPERATURE = 0.3     # Чуть больше \"творчества\" для описаний\n",
    "REPEAT_PENALTY = 1.1\n",
    "MAX_TOKENS = 300      # <-- Увеличиваем лимит, чтобы поместился развернутый ответ\n",
    "\n",
    "# --- 3. Функция сжатия (без изменений) ---\n",
    "def resize_and_save_image(original_path, output_path, max_size=(1024, 1024)):\n",
    "    with Image.open(original_path) as img:\n",
    "        img.thumbnail(max_size)\n",
    "        if img.mode in (\"RGBA\", \"P\"): img = img.convert(\"RGB\")\n",
    "        img.save(output_path, format='JPEG')\n",
    "    return output_path\n",
    "\n",
    "# --- 4. Загрузка модели (без изменений) ---\n",
    "llm = None\n",
    "if os.path.exists(MODEL_PATH) and os.path.exists(CLIP_MODEL_PATH):\n",
    "    print(\"Загрузка моделей...\")\n",
    "    try:\n",
    "        chat_handler = Llava15ChatHandler(clip_model_path=CLIP_MODEL_PATH, verbose=False)\n",
    "        llm = Llama(\n",
    "            model_path=MODEL_PATH, chat_handler=chat_handler,\n",
    "            n_ctx=N_CTX, n_gpu_layers=N_GPU_LAYERS, n_batch=N_BATCH, n_threads=N_THREADS, verbose=False\n",
    "        )\n",
    "        print(\"✅ Модели успешно загружены!\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ошибка загрузки моделей: {e}\")\n",
    "else:\n",
    "    print(f\"❌ Файл основной модели или CLIP не найден.\")\n",
    "\n",
    "# --- 5. Основной цикл обработки (без изменений, кроме вызова llm) ---\n",
    "if llm:\n",
    "    try:\n",
    "        image_files = sorted([f for f in os.listdir(IMG_DIR) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        results_data = []\n",
    "        \n",
    "        print(f\"Начинаем обработку {len(image_files)} изображений для получения развернутых ответов...\")\n",
    "        for filename in tqdm(image_files, desc=\"LLaVA Local 7B (Detailed)\"):\n",
    "            original_image_path = os.path.join(IMG_DIR, filename)\n",
    "            temp_image_path = os.path.join(TEMP_IMG_DIR, filename)\n",
    "            try:\n",
    "                resize_and_save_image(original_image_path, temp_image_path)\n",
    "                image_uri = pathlib.Path(temp_image_path).resolve().as_uri()\n",
    "                \n",
    "                prompt_for_llm = f\"USER: <image>\\n{PROMPT}\\nASSISTANT:\"\n",
    "                \n",
    "                response = llm(\n",
    "                    prompt_for_llm,\n",
    "                    stop=[\"USER:\"], # Достаточно одного стоп-слова\n",
    "                    max_tokens=MAX_TOKENS,\n",
    "                    temperature=TEMPERATURE,\n",
    "                    repeat_penalty=REPEAT_PENALTY\n",
    "                )\n",
    "                \n",
    "                result_text = response['choices'][0]['text'].strip()\n",
    "                results_data.append({\"filename\": filename, \"llava_7b_response\": result_text})\n",
    "\n",
    "            except Exception as e:\n",
    "                results_data.append({\"filename\": filename, \"llava_7b_response\": f\"Error: {e}\"})\n",
    "        \n",
    "        df_results = pd.DataFrame(results_data)\n",
    "        df_results.to_csv(RESULTS_FILE, index=False, encoding='utf-8')\n",
    "        print(f\"\\n✅ Результаты сохранены в '{RESULTS_FILE}'.\")\n",
    "        display(df_results.head())\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ Ошибка: Директория '{IMG_DIR}' не найдена.\")\n",
    "else:\n",
    "    print(\"\\n❌ Основной процесс не был запущен, так как модели не были загружены.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
