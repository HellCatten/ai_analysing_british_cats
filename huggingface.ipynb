{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc95531e",
   "metadata": {},
   "source": [
    "# Решить задачу с определением породы кошки. Британская это порода или нет.\n",
    "\n",
    "Для решения используем провайдеры LLM на Hugging face\n",
    "\n",
    "Сравниваем метрики двух выбранных LLM\n",
    "\n",
    "Выборка:\n",
    "- Британские кошки\n",
    "- Фотографии обычных кошек\n",
    "- Шотландские вислоухие\n",
    "- Русская голубая\n",
    "\n",
    "brit1-10. Фотографии 100% британских кошек голубого окраса.\n",
    "brithard. Кошки другого окраса, либо с отсутствием каких-либо признаков (закрытые глаза).\n",
    "random. Обычные кошки.\n",
    "rus. Русская голубая\n",
    "scot. Шотландая вислоухая.\n",
    "\n",
    "Основные признаки:\n",
    "- Британская. Большие, упитанные. Серая шертсть, оранжевые (миндальные) глаза.\n",
    "- Шотлансдая. Серая шерсть. Из отличий - вислоухость, меньше британской.\n",
    "- Русская. Такая же серая кошка. Отличия - меньше и глаза голубые, а не оранжевые.\n",
    "\n",
    "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\n",
    "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"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363056c5",
   "metadata": {},
   "source": [
    "Устанавливаем все необходимые библиотеки. \n",
    "\n",
    "Эту ячейку достаточно запустить один раз.\n",
    "\n",
    "pip install --upgrade requests Pillow pandas tqdm python-dotenv huggingface_hub ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef4fe8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Токен найден. Инициализируем InferenceClient.\n",
      "\n",
      "Найдено 30 изображений для обработки.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка изображений: 100%|██████████| 30/30 [00:16<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сбор данных завершен. Вот первые 5 результатов:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>model_1_response</th>\n",
       "      <th>model_2_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brit1.jpg</td>\n",
       "      <td>Error: BadRequestError, (Request ID: Root=1-69...</td>\n",
       "      <td>Error: BadRequestError, (Request ID: Root=1-69...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brit10.jpg</td>\n",
       "      <td>Error: BadRequestError, (Request ID: Root=1-69...</td>\n",
       "      <td>Error: BadRequestError, (Request ID: Root=1-69...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brit2.jpg</td>\n",
       "      <td>Error: BadRequestError, (Request ID: Root=1-69...</td>\n",
       "      <td>Error: BadRequestError, (Request ID: Root=1-69...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brit3.jpg</td>\n",
       "      <td>Error: BadRequestError, (Request ID: Root=1-69...</td>\n",
       "      <td>Error: BadRequestError, (Request ID: Root=1-69...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brit4.jpg</td>\n",
       "      <td>Error: BadRequestError, (Request ID: Root=1-69...</td>\n",
       "      <td>Error: BadRequestError, (Request ID: Root=1-69...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename                                   model_1_response  \\\n",
       "0   brit1.jpg  Error: BadRequestError, (Request ID: Root=1-69...   \n",
       "1  brit10.jpg  Error: BadRequestError, (Request ID: Root=1-69...   \n",
       "2   brit2.jpg  Error: BadRequestError, (Request ID: Root=1-69...   \n",
       "3   brit3.jpg  Error: BadRequestError, (Request ID: Root=1-69...   \n",
       "4   brit4.jpg  Error: BadRequestError, (Request ID: Root=1-69...   \n",
       "\n",
       "                                    model_2_response  \n",
       "0  Error: BadRequestError, (Request ID: Root=1-69...  \n",
       "1  Error: BadRequestError, (Request ID: Root=1-69...  \n",
       "2  Error: BadRequestError, (Request ID: Root=1-69...  \n",
       "3  Error: BadRequestError, (Request ID: Root=1-69...  \n",
       "4  Error: BadRequestError, (Request ID: Root=1-69...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Результаты сохранены в файл: llm_comparison_results.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display\n",
    "from huggingface_hub import InferenceClient\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "\n",
    "# --- 1. Загрузка и верификация токена ---\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "token_looks_valid = False\n",
    "if HF_TOKEN:\n",
    "    print(\"✅ Токен найден. Инициализируем InferenceClient.\")\n",
    "    try:\n",
    "        client = InferenceClient(token=HF_TOKEN)\n",
    "        token_looks_valid = True\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Не удалось инициализировать клиент: {e}\")\n",
    "else:\n",
    "    print(\"❌ Токен не найден или не изменен. Проверьте ваш .env файл.\")\n",
    "\n",
    "# --- 2. Основной цикл (запускается, если клиент создан) ---\n",
    "if token_looks_valid:\n",
    "    # --- Конфигурация с НОВЫМИ моделями ---\n",
    "    MODEL_1_ID = \"lmms-lab/LLaVA-OneVision-1.5-8B-Instruct\"\n",
    "    MODEL_2_ID = \"PsiPi/NousResearch_Nous-Hermes-2-Vision-GGUF\"\n",
    "    \n",
    "    IMG_DIR = \"img\"\n",
    "    PROMPT = \"Скажи, изображена ли на данном фото кошка породы \\\"Британская короткошерстная\\\", дай коротки ответ \\\"да\\\" или \\\"нет\\\". Опиши одним словом каждый признак, который убедил тебя в правильности или неправильности ответа. Если это не британская короткошерстная кошка, скажи какая это порода.\"\n",
    "\n",
    "    # --- НОВАЯ ФУНКЦИЯ: Изменение размера изображения ---\n",
    "    def resize_image(image_path, max_size=(1024, 1024)):\n",
    "        \"\"\"Открывает изображение, изменяет его размер и возвращает в виде байтов.\"\"\"\n",
    "        with Image.open(image_path) as img:\n",
    "            img.thumbnail(max_size)\n",
    "            # Сохраняем измененное изображение в байтовый поток в памяти\n",
    "            byte_arr = io.BytesIO()\n",
    "            # Убедимся, что сохраняем в формате, который не поддерживает прозрачность (если исходник был PNG)\n",
    "            if img.mode in (\"RGBA\", \"P\"):\n",
    "                img = img.convert(\"RGB\")\n",
    "            img.save(byte_arr, format='JPEG')\n",
    "            return byte_arr.getvalue()\n",
    "\n",
    "    # --- Обновленная функция для запроса ---\n",
    "    def query_chat_model(image_path, model_id, prompt):\n",
    "        try:\n",
    "            # <-- НОВЫЙ ШАГ: Изменение размера изображения перед кодированием\n",
    "            resized_image_bytes = resize_image(image_path)\n",
    "            \n",
    "            # Кодируем в base64 уже измененное, маленькое изображение\n",
    "            img_base64 = base64.b64encode(resized_image_bytes).decode('utf-8')\n",
    "            \n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img_base64}\"}},\n",
    "                        {\"type\": \"text\", \"text\": prompt}\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "\n",
    "            response = client.chat_completion(\n",
    "                messages=messages,\n",
    "                model=model_id,\n",
    "                max_tokens=100\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Error: {type(e).__name__}, {e}\"\n",
    "\n",
    "    # --- Цикл обработки ---\n",
    "    try:\n",
    "        image_files = [f for f in os.listdir(IMG_DIR) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        print(f\"\\nНайдено {len(image_files)} изображений для обработки.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Ошибка: Директория '{IMG_DIR}' не найдена.\")\n",
    "        image_files = []\n",
    "\n",
    "    results_data = []\n",
    "    if image_files:\n",
    "        for filename in tqdm(image_files, desc=\"Обработка изображений\"):\n",
    "            image_path = os.path.join(IMG_DIR, filename)\n",
    "            response_1 = query_chat_model(image_path, MODEL_1_ID, PROMPT)\n",
    "            response_2 = query_chat_model(image_path, MODEL_2_ID, PROMPT)\n",
    "            results_data.append({\n",
    "                \"filename\": filename,\n",
    "                \"model_1_response\": response_1,\n",
    "                \"model_2_response\": response_2\n",
    "            })\n",
    "        \n",
    "        df_results = pd.DataFrame(results_data)\n",
    "        \n",
    "        print(\"\\nСбор данных завершен. Вот первые 5 результатов:\")\n",
    "        display(df_results.head())\n",
    "        \n",
    "        output_csv_path = \"llm_comparison_results.csv\"\n",
    "        df_results.to_csv(output_csv_path, index=False, encoding='utf-8')\n",
    "        print(f\"✅ Результаты сохранены в файл: {output_csv_path}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Нет файлов для обработки.\")\n",
    "else:\n",
    "    print(\"\\nОсновной процесс не был запущен.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a6fdaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Результаты успешно сохранены в файл: llm_comparison_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Проверяем, существует ли переменная df_results, прежде чем сохранять\n",
    "if 'df_results' in locals() and not df_results.empty:\n",
    "    output_csv_path = \"llm_comparison_results.csv\"\n",
    "    df_results.to_csv(output_csv_path, index=False, encoding='utf-8')\n",
    "    print(f\"✅ Результаты успешно сохранены в файл: {output_csv_path}\")\n",
    "else:\n",
    "    print(\"❌ Таблица с результатами пуста или не существует. Сохранение не выполнено.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
